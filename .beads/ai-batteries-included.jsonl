{"id":"rush-ai","title":"AI Agent Batteries Included","description":"Transform Rush into the ideal shell for AI coding agents by providing structured, parseable output and native data handling.\n\n## Motivation\nAI coding agents (like Claude Code) make hundreds of shell calls per task. They currently suffer from:\n- Parsing unstructured text output (fragile, slow)\n- Spawning jq/external tools for JSON (overhead)\n- Insufficient error context (can't respond intelligently)\n- Performance bottlenecks at scale\n\n## Target Users\nPrimarily: AI coding assistants (Claude Code, Cursor, Copilot Workspace, etc.)\nSecondarily: Human developers who want structured data\n\n## Success Criteria\n- All git commands return structured JSON (--json flag)\n- Native JSON parsing and querying (no jq needed)\n- All file operations support --json output\n- HTTP fetch builtin for API/docs access\n- Structured error responses with error types\n- 10x faster than bash+jq for common agent workflows\n- Documentation with AI agent examples\n\n## Design Principles\n1. **Dual-mode**: Human-friendly by default, `--json` for structured output\n2. **Performance**: Native Rust, no subprocess overhead\n3. **Reliability**: Typed data, predictable output format\n4. **Composition**: Structured data flows through pipes\n5. **Error clarity**: Machine-readable error types\n\n## Competitive Advantage\nWhat makes Rush better than bash+jq for AI agents:\n- **Speed**: 10-100x faster (no process spawning)\n- **Integration**: Commands share state, optimize together\n- **Reliability**: Type-safe, no string parsing bugs\n- **Simplicity**: One tool, not a pipeline of tools","status":"open","priority":1,"issue_type":"epic","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","batteries-included","epic","json","phase5"]}
{"id":"rush-ai.1","title":"AI-001: Structured git log with JSON output","description":"As an AI coding agent, I need git log to return structured JSON so I can analyze commit history programmatically without fragile parsing.\n\n## Priority: P0 - CRITICAL\nGit log is queried constantly by AI agents to understand code evolution, find relevant commits, and generate changelogs.\n\n## Acceptance Criteria\n- [ ] `git_log` builtin command implemented\n- [ ] Human-readable output by default (like git log --oneline)\n- [ ] `git_log --json` returns structured JSON array\n- [ ] JSON includes: hash, author, date, message, files_changed\n- [ ] `git_log --json -n N` limits to N commits\n- [ ] `git_log --json --since=\"1 week ago\"` date filtering\n- [ ] `git_log --json path/to/file` file-specific history\n- [ ] `git_log --json --grep=\"pattern\"` search messages\n- [ ] Performance: \u003c5ms for 100 commits on large repos\n- [ ] Error handling: clear messages for non-git repos\n- [ ] cargo test passes with integration tests\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Get recent commits for context\ngit_log --json -n 10\n# Returns:\n# [\n#   {\n#     \"hash\": \"a1b2c3d\",\n#     \"short_hash\": \"a1b2c3d\",\n#     \"author\": \"Alice \u003calice@example.com\u003e\",\n#     \"date\": \"2026-01-24T12:00:00Z\",\n#     \"timestamp\": 1706097600,\n#     \"message\": \"Add user authentication\",\n#     \"files_changed\": 5,\n#     \"insertions\": 123,\n#     \"deletions\": 45\n#   },\n#   ...\n# ]\n\n# AI agent: Find commits related to auth\ngit_log --json --grep=\"auth\" -n 20\n\n# AI agent: Get file history\ngit_log --json src/auth.rs\n\n# Human: Quick overview\ngit_log -n 10\n# a1b2c3d Add user authentication\n# b2c3d4e Fix login bug\n# ...\n```\n\n## Technical Implementation\n1. **Create src/builtins/git_log.rs**\n   - Leverage existing GitContext from git_status.rs\n   - Use git2-rs crate (already in dependencies)\n   - Parse flags: --json, -n, --since, --grep, paths\n\n2. **Data Structure**\n   ```rust\n   #[derive(Serialize)]\n   struct Commit {\n       hash: String,\n       short_hash: String,\n       author: String,\n       author_email: String,\n       date: String,  // ISO 8601\n       timestamp: i64,\n       message: String,\n       files_changed: usize,\n       insertions: usize,\n       deletions: usize,\n   }\n   ```\n\n3. **Output Modes**\n   - Default: `{short_hash} {message_first_line}`\n   - `--json`: JSON array of Commit objects\n   - Pipe to jq-compatible format\n\n4. **Performance Optimization**\n   - Lazy loading (don't compute stats unless needed)\n   - Limit default to 100 commits\n   - Cache git2 repo handle in GitContext\n\n5. **Error Handling**\n   - Not a git repo: clear error message\n   - Invalid refs: helpful suggestion\n   - Permission errors: actionable message\n\n## Testing Strategy\n- Unit tests: parsing, formatting, edge cases\n- Integration tests:\n  - git_log in actual repo\n  - --json output validation\n  - Filter flags work correctly\n  - Performance benchmark (\u003c5ms for 100 commits)\n- Error cases: non-git repo, invalid flags\n\n## Documentation\n- Add to README.md examples\n- Create docs/AI_AGENT_GIT.md with:\n  - All git_log use cases for AI agents\n  - JSON schema reference\n  - Performance characteristics\n  - Comparison with git log + parsing\n\n## Dependencies\n- git2-rs crate (already in Cargo.toml)\n- serde_json for JSON serialization\n- Extends GitContext from src/git.rs\n\n## Estimated Effort\n40-50k tokens:\n- Implementation: 20k\n- Tests: 15k\n- Documentation: 10k\n- Debugging/refinement: 5k","status":"open","priority":1,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","critical","git","json","p0"],"dependencies":[{"issue_id":"rush-ai.1","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.2","title":"AI-002: Structured git diff with JSON output","description":"As an AI coding agent, I need git diff to return structured JSON so I can analyze code changes programmatically and generate smart commit messages.\n\n## Priority: P0 - CRITICAL\nGit diff is the #1 most-called git command by AI agents - used for commit message generation, code review, change analysis.\n\n## Acceptance Criteria\n- [ ] `git_diff` builtin command implemented\n- [ ] Human-readable unified diff by default\n- [ ] `git_diff --json` returns structured JSON\n- [ ] JSON includes: files, hunks, line changes, stats\n- [ ] `git_diff --json --staged` for staged changes\n- [ ] `git_diff --json HEAD~1..HEAD` commit ranges\n- [ ] `git_diff --json --stat` summary statistics only\n- [ ] `git_diff --json file.txt` specific file diff\n- [ ] Performance: \u003c10ms for typical diffs (\u003c1000 lines)\n- [ ] Handles binary files gracefully\n- [ ] cargo test passes with integration tests\n- [ ] cargo build --release succeeds  \n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Analyze unstaged changes for commit message\ngit_diff --json\n# Returns:\n# {\n#   \"files\": [\n#     {\n#       \"path\": \"src/auth.rs\",\n#       \"status\": \"modified\",\n#       \"additions\": 15,\n#       \"deletions\": 3,\n#       \"hunks\": [\n#         {\n#           \"old_start\": 42,\n#           \"old_lines\": 5,\n#           \"new_start\": 42,\n#           \"new_lines\": 10,\n#           \"header\": \"@@ -42,5 +42,10 @@ impl Auth {\",\n#           \"changes\": [\n#             {\"type\": \"context\", \"line\": \"fn login() {\"},\n#             {\"type\": \"delete\", \"line\": \"    // TODO: implement\"},\n#             {\"type\": \"add\", \"line\": \"    let token = generate_token();\"},\n#             {\"type\": \"add\", \"line\": \"    validate_token(token)\"}\n#           ]\n#         }\n#       ]\n#     }\n#   ],\n#   \"summary\": {\n#     \"files_changed\": 1,\n#     \"insertions\": 15,\n#     \"deletions\": 3\n#   }\n# }\n\n# AI agent: Just get summary stats\ngit_diff --json --stat\n# {\"files_changed\": 3, \"insertions\": 45, \"deletions\": 12}\n\n# AI agent: Staged changes for commit message\ngit_diff --json --staged\n\n# Human: normal diff\ngit_diff src/auth.rs\n```\n\n## Technical Implementation\n1. **Create src/builtins/git_diff.rs**\n   - Use git2-rs Diff API\n   - Parse flags: --json, --staged, --stat, paths, ranges\n   - Handle both working tree and staged diffs\n\n2. **Data Structures**\n   ```rust\n   #[derive(Serialize)]\n   struct DiffOutput {\n       files: Vec\u003cFileDiff\u003e,\n       summary: DiffSummary,\n   }\n   \n   #[derive(Serialize)]\n   struct FileDiff {\n       path: String,\n       old_path: Option\u003cString\u003e,  // for renames\n       status: FileStatus,  // modified, added, deleted, renamed\n       additions: usize,\n       deletions: usize,\n       hunks: Vec\u003cHunk\u003e,\n   }\n   \n   #[derive(Serialize)]\n   struct Hunk {\n       old_start: u32,\n       old_lines: u32,\n       new_start: u32,\n       new_lines: u32,\n       header: String,\n       changes: Vec\u003cLineChange\u003e,\n   }\n   \n   #[derive(Serialize)]\n   struct LineChange {\n       change_type: ChangeType,  // context, add, delete\n       line: String,\n   }\n   ```\n\n3. **Output Modes**\n   - Default: Standard unified diff format\n   - `--json`: Full structured output with hunks\n   - `--json --stat`: Summary only (fast)\n   - `--json --name-only`: Just file paths\n\n4. **Performance Optimization**\n   - Lazy hunk parsing (skip if --stat only)\n   - Streaming for large diffs\n   - Limit line context to Â±3 lines by default\n\n5. **Edge Cases**\n   - Binary files: include in files array but no hunks\n   - Renames: show old_path and new_path\n   - New files: status=\"added\", no old content\n   - Deleted files: status=\"deleted\", no new content\n\n## Testing Strategy\n- Unit tests: diff parsing, JSON serialization\n- Integration tests:\n  - Simple file modification\n  - Multiple files changed\n  - File rename detection\n  - Binary files\n  - Large diffs (performance)\n  - Staged vs unstaged\n  - Commit ranges\n- Error cases: invalid refs, permission errors\n\n## Documentation\n- Add to docs/AI_AGENT_GIT.md\n- JSON schema reference\n- Common AI agent patterns:\n  - Commit message generation\n  - Code review analysis\n  - Change summarization\n- Performance guide\n\n## Dependencies\n- git2-rs crate\n- serde_json\n- Extends GitContext\n\n## Estimated Effort\n50-60k tokens:\n- Implementation: 25k (more complex than git_log)\n- Tests: 20k (many edge cases)\n- Documentation: 10k\n- Debugging: 5k","status":"open","priority":1,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","critical","git","json","p0"],"dependencies":[{"issue_id":"rush-ai.2","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.3","title":"AI-003: Extend git_status with --json and full file listing","description":"As an AI coding agent, I need git_status to return complete file listings and support JSON output so I can understand repository state without parsing text.\n\n## Priority: P0 - CRITICAL\nGit status is called on almost every agent action to understand what files have changed.\n\n## Acceptance Criteria\n- [ ] Extend existing src/builtins/git_status.rs\n- [ ] `git_status --json` returns structured JSON\n- [ ] Include all file categories: staged, unstaged, untracked\n- [ ] Include ahead/behind counts\n- [ ] Include current branch and tracking info\n- [ ] Include merge/rebase state if applicable\n- [ ] `git_status --json --porcelain` machine-readable format\n- [ ] Performance: \u003c5ms on repos with \u003c1000 files\n- [ ] Handle submodules gracefully\n- [ ] cargo test passes\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Get full repository state\ngit_status --json\n# Returns:\n# {\n#   \"branch\": \"feature/auth\",\n#   \"tracking\": \"origin/feature/auth\",\n#   \"ahead\": 2,\n#   \"behind\": 0,\n#   \"state\": \"clean\",  // or \"merge\", \"rebase\", \"cherry-pick\"\n#   \"staged\": [\n#     {\"path\": \"src/auth.rs\", \"status\": \"modified\"},\n#     {\"path\": \"tests/auth_test.rs\", \"status\": \"added\"}\n#   ],\n#   \"unstaged\": [\n#     {\"path\": \"src/main.rs\", \"status\": \"modified\"},\n#     {\"path\": \"README.md\", \"status\": \"modified\"}\n#   ],\n#   \"untracked\": [\n#     \"temp.txt\",\n#     \"debug.log\"\n#   ],\n#   \"conflicted\": [],\n#   \"summary\": {\n#     \"staged_count\": 2,\n#     \"unstaged_count\": 2,\n#     \"untracked_count\": 2,\n#     \"conflicted_count\": 0\n#   }\n# }\n\n# AI agent: Quick check if repo is dirty\ngit_status --json --porcelain | jq -r '.summary.unstaged_count'\n\n# Human: normal output (existing behavior)\ngit_status\n```\n\n## Current State Analysis\nLooking at src/builtins/git_status.rs:61-68:\n```rust\nif git_ctx.is_dirty() {\n    output.push_str(\"Changes not staged for commit:\\n\");\n    // TODO: List actual changed files\n} else {\n    output.push_str(\"nothing to commit, working tree clean\\n\");\n}\n```\n\n**This TODO is what we're implementing!**\n\n## Technical Implementation\n1. **Extend GitContext (src/git.rs)**\n   - Add methods:\n     - `staged_files() -\u003e Vec\u003c(PathBuf, Status)\u003e`\n     - `unstaged_files() -\u003e Vec\u003c(PathBuf, Status)\u003e`\n     - `untracked_files() -\u003e Vec\u003cPathBuf\u003e`\n     - `conflicted_files() -\u003e Vec\u003cPathBuf\u003e`\n   - Use git2::Repository::statuses()\n\n2. **Update src/builtins/git_status.rs**\n   - Add --json flag parsing\n   - Implement JSON serialization\n   - Fix the TODO: actually list files in human output\n   - Add file status details\n\n3. **Data Structure**\n   ```rust\n   #[derive(Serialize)]\n   struct GitStatusOutput {\n       branch: Option\u003cString\u003e,\n       tracking: Option\u003cString\u003e,\n       ahead: u32,\n       behind: u32,\n       state: RepoState,  // clean, merge, rebase, etc.\n       staged: Vec\u003cFileStatus\u003e,\n       unstaged: Vec\u003cFileStatus\u003e,\n       untracked: Vec\u003cString\u003e,\n       conflicted: Vec\u003cString\u003e,\n       summary: StatusSummary,\n   }\n   ```\n\n4. **Output Modes**\n   - Default: Enhanced human-readable (list actual files!)\n   - `--json`: Full structured output\n   - `--porcelain`: Git-compatible machine format\n\n5. **Performance**\n   - Cache status results in GitContext\n   - Lazy loading of file lists\n   - Ignore rules respected (.gitignore)\n\n## Testing Strategy\n- Unit tests: status categorization, JSON serialization\n- Integration tests:\n  - Clean repo\n  - Staged files only\n  - Unstaged files only\n  - Mixed state\n  - Untracked files\n  - Merge conflicts\n  - Ahead/behind tracking\n- Performance: benchmark on large repos\n\n## Documentation\n- Update existing git_status docs\n- Add JSON schema\n- Add AI agent examples\n- Document performance characteristics\n\n## Dependencies\n- Extends existing git_status.rs and GitContext\n- git2-rs (already in use)\n- serde_json\n\n## Estimated Effort\n35-45k tokens:\n- GitContext extension: 10k\n- git_status update: 15k\n- Tests: 12k\n- Documentation: 8k","status":"open","priority":1,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","critical","git","json","p0"],"dependencies":[{"issue_id":"rush-ai.3","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.4","title":"AI-004: JSON query and manipulation builtins","description":"As an AI coding agent, I need native JSON parsing and querying so I don't have to spawn jq for every JSON operation.\n\n## Priority: P1 - HIGH\nAI agents constantly work with JSON (API responses, config files, structured command output). Spawning jq adds 10-50ms overhead per call.\n\n## Acceptance Criteria\n- [ ] `json_get` builtin: extract values from JSON\n- [ ] `json_set` builtin: modify JSON values\n- [ ] `json_query` builtin: JSONPath or jq-like queries\n- [ ] Pipe support: `cat file.json | json_get '.user.name'`\n- [ ] File support: `json_get '.data' file.json`\n- [ ] Array indexing: `json_get '.[0].name'`\n- [ ] Multiple queries: `json_get '.name' '.email' '.age'`\n- [ ] Error handling: clear messages for invalid JSON/paths\n- [ ] Performance: \u003c1ms for typical queries (\u003c100KB JSON)\n- [ ] cargo test passes with extensive tests\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Extract value from API response\ncurl -s api.example.com/user | json_get '.name'\n# \"Alice\"\n\n# AI agent: Navigate nested structures\necho '{\"user\":{\"profile\":{\"age\":30}}}' | json_get '.user.profile.age'\n# 30\n\n# AI agent: Array operations\necho '[{\"name\":\"Alice\"},{\"name\":\"Bob\"}]' | json_get '.[].name'\n# Alice\n# Bob\n\n# AI agent: Multiple fields\ngit_status --json | json_get '.branch' '.ahead' '.behind'\n# feature/auth\n# 2\n# 0\n\n# AI agent: Modify JSON\necho '{\"count\":5}' | json_set '.count' 10\n# {\"count\":10}\n\n# AI agent: Query with filter\njson_query '.files[] | select(.status == \"modified\")' changes.json\n```\n\n## Technical Implementation\n1. **Create src/builtins/json.rs**\n   - Three main functions: json_get, json_set, json_query\n   - Use serde_json for parsing\n   - Use serde_json::Value for manipulation\n   - Consider jsonpath_lib or similar for path queries\n\n2. **Query Syntax**\n   Start simple, expand as needed:\n   - `.field` - get field\n   - `.field.nested` - nested access\n   - `.[0]` - array index\n   - `.[]` - array iteration\n   - Later: filters, functions (like jq)\n\n3. **Data Flow**\n   ```rust\n   // Input sources\n   enum JsonSource {\n       Stdin(String),\n       File(PathBuf),\n       Argument(String),\n   }\n   \n   // Parse -\u003e Query -\u003e Output\n   fn json_get(path: \u0026str, source: JsonSource) -\u003e Result\u003cValue\u003e {\n       let json: Value = parse_source(source)?;\n       let result = query_path(\u0026json, path)?;\n       Ok(result)\n   }\n   ```\n\n4. **Output Formats**\n   - Raw value (no quotes for primitives)\n   - JSON (for objects/arrays)\n   - `--raw` flag for unquoted strings\n   - `--compact` vs `--pretty` for objects\n\n5. **Error Handling**\n   - Invalid JSON: show line/column\n   - Invalid path: show where it failed\n   - Type errors: \"expected array, got object\"\n\n## Performance Optimization\n- Lazy parsing (don't parse if not needed)\n- Streaming for large files (consider json-stream)\n- Cache parsed JSON for multiple queries\n- Benchmark vs jq\n\n## Testing Strategy\n- Unit tests:\n  - Path parsing\n  - Query execution\n  - Edge cases (null, empty, nested)\n- Integration tests:\n  - Pipe input\n  - File input\n  - Multiple queries\n  - Error cases\n- Performance tests:\n  - Small JSON (\u003c1KB): \u003c0.1ms\n  - Medium JSON (100KB): \u003c1ms\n  - Large JSON (10MB): \u003c50ms\n- Comparison: Rush vs jq on same queries\n\n## Documentation\n- Create docs/JSON_BUILTINS.md:\n  - All query syntax\n  - Examples for AI agents\n  - Performance guide\n  - Migration from jq\n- Add to README examples\n- Inline help for each builtin\n\n## Future Extensions (not in this bead)\n- `json_merge`: combine multiple JSON files\n- `json_validate`: schema validation\n- `json_format`: pretty-print\n- Full jq compatibility layer\n\n## Dependencies\n- serde_json (already in use)\n- Consider: jsonpath_lib, jq-rs, or implement simple path parser\n\n## Estimated Effort\n50-60k tokens:\n- Implementation (3 builtins): 25k\n- Path query parser: 10k\n- Tests: 15k\n- Documentation: 10k","status":"open","priority":2,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","json","p1"],"dependencies":[{"issue_id":"rush-ai.4","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.5","title":"AI-005: Add --json flag to ls builtin","description":"As an AI coding agent, I need ls to output structured JSON so I can process file listings programmatically without parsing text columns.\n\n## Priority: P1 - HIGH\nLs is one of the most-called commands by AI agents. Text parsing is fragile (spaces in filenames, different ls implementations).\n\n## Acceptance Criteria\n- [ ] Extend existing src/builtins/ls.rs\n- [ ] `ls --json` returns JSON array of file objects\n- [ ] Include: name, path, size, modified, type, permissions\n- [ ] `ls --json -l` includes full metadata\n- [ ] `ls --json -R` recursive directory tree\n- [ ] Handle symlinks: include target info\n- [ ] Handle errors gracefully (permission denied, etc.)\n- [ ] Performance: \u003c5ms for \u003c1000 files\n- [ ] Works with all existing ls flags (filter, sort)\n- [ ] cargo test passes\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Get file listing with metadata\nls --json src/\n# [\n#   {\n#     \"name\": \"main.rs\",\n#     \"path\": \"src/main.rs\",\n#     \"type\": \"file\",\n#     \"size\": 4523,\n#     \"modified\": \"2026-01-24T12:00:00Z\",\n#     \"permissions\": \"rw-r--r--\",\n#     \"mode\": 420\n#   },\n#   {\n#     \"name\": \"lib.rs\",\n#     \"path\": \"src/lib.rs\",\n#     \"type\": \"file\",\n#     \"size\": 1234,\n#     \"modified\": \"2026-01-23T10:30:00Z\",\n#     \"permissions\": \"rw-r--r--\",\n#     \"mode\": 420\n#   },\n#   {\n#     \"name\": \"builtins\",\n#     \"path\": \"src/builtins\",\n#     \"type\": \"directory\",\n#     \"size\": 4096,\n#     \"modified\": \"2026-01-24T11:00:00Z\",\n#     \"permissions\": \"rwxr-xr-x\",\n#     \"mode\": 493\n#   }\n# ]\n\n# AI agent: Find large files\nls --json -R | json_query '.[] | select(.size \u003e 1000000)'\n\n# AI agent: Get just Rust files with metadata\nls --json src/*.rs\n\n# AI agent: Check if file exists and get size\nls --json file.txt | json_get '.[0].size'\n\n# Human: normal ls (existing behavior)\nls -la\n```\n\n## Current State Analysis\nLooking at existing ls.rs, it already:\n- Handles color output\n- Sorts files\n- Shows hidden files\n- Long format (-l)\n\nWe need to add:\n- JSON output mode\n- Structured metadata\n- Recursive JSON tree\n\n## Technical Implementation\n1. **Extend src/builtins/ls.rs**\n   - Add --json flag parsing\n   - Add OutputFormat enum (Human | Json)\n   - Extract metadata collection into separate function\n   - Implement JSON serialization\n\n2. **Data Structure**\n   ```rust\n   #[derive(Serialize)]\n   struct FileEntry {\n       name: String,\n       path: PathBuf,\n       file_type: FileType,  // file, directory, symlink\n       size: u64,\n       modified: String,  // ISO 8601\n       modified_timestamp: i64,\n       permissions: String,  // \"rw-r--r--\"\n       mode: u32,  // Unix mode bits\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       symlink_target: Option\u003cPathBuf\u003e,\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       owner: Option\u003cString\u003e,  // Unix only\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       group: Option\u003cString\u003e,  // Unix only\n   }\n   \n   #[derive(Serialize)]\n   enum FileType {\n       File,\n       Directory,\n       Symlink,\n       Other,\n   }\n   ```\n\n3. **Output Modes**\n   - Default: Current human-readable format (no changes)\n   - `--json`: JSON array of FileEntry objects\n   - `--json -l`: Include owner/group if available\n   - `--json -R`: Nested structure with children arrays\n\n4. **Recursive Structure**\n   ```rust\n   #[derive(Serialize)]\n   struct DirectoryEntry {\n       name: String,\n       path: PathBuf,\n       // ... other fields ...\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       children: Option\u003cVec\u003cDirectoryEntry\u003e\u003e,\n   }\n   ```\n\n5. **Error Handling**\n   - Permission denied: include error in entry\n   - Broken symlinks: include in output with target=null\n   - Invalid UTF-8: use lossy conversion\n\n## Performance Optimization\n- Parallel metadata collection for large directories\n- Lazy stat() calls (only when needed)\n- Limit recursive depth to prevent stack overflow\n\n## Testing Strategy\n- Unit tests: metadata extraction, JSON serialization\n- Integration tests:\n  - Simple directory\n  - Recursive listing\n  - Symlinks\n  - Permission errors\n  - Empty directory\n  - Large directory (performance)\n- Cross-platform: Windows vs Unix permissions\n\n## Documentation\n- Update existing ls docs\n- Add JSON schema reference\n- Add AI agent examples\n- Document performance characteristics\n- Create docs/AI_AGENT_FILES.md\n\n## Dependencies\n- Extends existing ls.rs\n- serde_json\n- No new external crates needed\n\n## Estimated Effort\n35-45k tokens:\n- Implementation: 15k\n- Recursive support: 10k\n- Tests: 12k\n- Documentation: 8k","status":"open","priority":2,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","enhancement","json","p1"],"dependencies":[{"issue_id":"rush-ai.5","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.5","depends_on_id":"rush-ai.4","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.6","title":"AI-006: Add --json flag to find and grep builtins","description":"As an AI coding agent, I need find and grep to output structured JSON so I can process search results programmatically.\n\n## Priority: P1 - HIGH\nFind and grep are core search tools. AI agents use them constantly but have to parse line-oriented output.\n\n## Acceptance Criteria\n- [ ] Extend src/builtins/find.rs: add --json flag\n- [ ] Extend src/builtins/grep.rs: add --json flag\n- [ ] find --json: array of file paths with metadata\n- [ ] grep --json: array of matches with line numbers, context\n- [ ] find --json -type f: filter by type in structured output\n- [ ] grep --json -C 2: include context lines in structure\n- [ ] Performance: no slowdown vs text output\n- [ ] All existing flags work with --json\n- [ ] cargo test passes for both\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n\n### Find with JSON\n```bash\n# AI agent: Find all Rust files with metadata\nfind --json src/ -name \"*.rs\"\n# [\n#   {\n#     \"path\": \"src/main.rs\",\n#     \"type\": \"file\",\n#     \"size\": 4523,\n#     \"modified\": \"2026-01-24T12:00:00Z\"\n#   },\n#   {\n#     \"path\": \"src/lib.rs\",\n#     \"type\": \"file\",\n#     \"size\": 1234,\n#     \"modified\": \"2026-01-23T10:30:00Z\"\n#   }\n# ]\n\n# AI agent: Find files modified today\nfind --json . -mtime -1 | json_query '.[] | .path'\n```\n\n### Grep with JSON\n```bash\n# AI agent: Find all TODO comments with context\ngrep --json \"TODO\" src/**/*.rs\n# [\n#   {\n#     \"file\": \"src/builtins/git_status.rs\",\n#     \"line_number\": 66,\n#     \"match\": \"// TODO: List actual changed files\",\n#     \"context_before\": [\n#       \"if git_ctx.is_dirty() {\",\n#       \"    output.push_str(\\\"Changes not staged for commit:\\\\n\\\");\"\n#     ],\n#     \"context_after\": [\n#       \"} else {\",\n#       \"    output.push_str(\\\"nothing to commit\\\");\"\n#     ]\n#   }\n# ]\n\n# AI agent: Count matches per file\ngrep --json \"fn \" src/*.rs | json_query 'group_by(.file) | map({file: .[0].file, count: length})'\n\n# AI agent: Get just matching lines\ngrep --json \"error\" logfile.txt | json_get '.[].match'\n```\n\n## Technical Implementation\n\n### Find JSON Output\n1. **Extend src/builtins/find.rs**\n   ```rust\n   #[derive(Serialize)]\n   struct FindResult {\n       path: PathBuf,\n       file_type: FileType,\n       size: u64,\n       modified: String,\n       modified_timestamp: i64,\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       permissions: Option\u003cString\u003e,\n   }\n   ```\n\n2. **Collect results, serialize at end**\n   - Store all FindResult objects\n   - Output JSON array when search completes\n   - Maintain same search logic, different output\n\n### Grep JSON Output\n1. **Extend src/builtins/grep.rs**\n   ```rust\n   #[derive(Serialize)]\n   struct GrepMatch {\n       file: PathBuf,\n       line_number: usize,\n       column: Option\u003cusize\u003e,  // if available\n       match_text: String,\n       full_line: String,\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       context_before: Option\u003cVec\u003cString\u003e\u003e,\n       #[serde(skip_serializing_if = \"Option::is_none\")]\n       context_after: Option\u003cVec\u003cString\u003e\u003e,\n   }\n   ```\n\n2. **Context Handling**\n   - Parse -A, -B, -C flags\n   - Include context lines in JSON\n   - Track line numbers correctly\n\n## Output Modes\n- Default: Current text output (no changes)\n- `--json`: Array of result objects\n- `--json --count`: Just counts, not full results\n- Compatible with all existing flags\n\n## Performance Considerations\n- JSON serialization shouldn't slow down search\n- Stream results for very large outputs (consider JSONL)\n- Benchmark vs text mode\n\n## Testing Strategy\n- **Find tests:**\n  - Simple file search\n  - Type filtering\n  - Name patterns\n  - Time-based filters\n  - Large directory trees\n- **Grep tests:**\n  - Simple pattern match\n  - Multiple files\n  - Context lines\n  - Line numbers\n  - Binary file handling\n  - Large files\n- Cross-platform: path separators, permissions\n\n## Documentation\n- Update find.rs and grep.rs docs\n- Add to docs/AI_AGENT_FILES.md\n- JSON schema reference for both\n- Performance comparison\n- Migration guide from text parsing\n\n## Dependencies\n- Extends existing find.rs and grep.rs\n- serde_json\n- regex crate (already in use for grep)\n\n## Estimated Effort\n45-55k tokens:\n- Find implementation: 12k\n- Grep implementation: 15k\n- Tests (both): 15k\n- Documentation: 8k\n- Integration: 5k","status":"open","priority":2,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","enhancement","json","p1"],"dependencies":[{"issue_id":"rush-ai.6","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.6","depends_on_id":"rush-ai.4","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.7","title":"AI-007: HTTP fetch builtin with structured responses","description":"As an AI coding agent, I need a native HTTP client so I can fetch documentation, APIs, and package info without spawning curl.\n\n## Priority: P2 - MEDIUM\nAI agents frequently need to fetch external resources (docs, package registries, APIs). Currently requires curl + JSON parsing.\n\n## Acceptance Criteria\n- [ ] `fetch` builtin command implemented\n- [ ] `fetch URL` performs GET request\n- [ ] `fetch --json URL` returns structured response\n- [ ] `fetch -X POST -d 'data' URL` POST requests\n- [ ] `fetch -H \"Header: value\" URL` custom headers\n- [ ] JSON response body automatically parsed\n- [ ] `fetch --timeout 5 URL` request timeout\n- [ ] Follow redirects by default, `--no-follow` to disable\n- [ ] Error handling: network errors, timeouts, HTTP errors\n- [ ] Performance: comparable to curl\n- [ ] cargo test passes\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Fetch API data\nfetch --json https://api.github.com/repos/rust-lang/rust\n# {\n#   \"status\": 200,\n#   \"headers\": {\n#     \"content-type\": \"application/json\",\n#     \"...\": \"...\"\n#   },\n#   \"body\": {\n#     \"name\": \"rust\",\n#     \"description\": \"Empowering everyone...\",\n#     \"stars\": 95000,\n#     ...\n#   },\n#   \"response_time_ms\": 234\n# }\n\n# AI agent: Check if URL is reachable\nfetch --json --method HEAD https://example.com | json_get '.status'\n# 200\n\n# AI agent: POST JSON data\necho '{\"title\":\"test\"}' | fetch --json -X POST -H \"Content-Type: application/json\" -d @- https://api.example.com/posts\n\n# AI agent: Get just response body\nfetch https://api.example.com/data\n# {\"result\": \"success\"}\n\n# AI agent: Download with error handling\nif fetch --timeout 5 https://example.com/large-file -o output.bin; then\n  echo \"Downloaded successfully\"\nelse\n  echo \"Download failed: $?\"\nfi\n```\n\n## Technical Implementation\n1. **Create src/builtins/fetch.rs**\n   - Use reqwest crate (popular, well-maintained)\n   - Parse HTTP-like CLI arguments\n   - Execute request\n   - Format response\n\n2. **Data Structure**\n   ```rust\n   #[derive(Serialize)]\n   struct FetchResponse {\n       status: u16,\n       status_text: String,\n       headers: HashMap\u003cString, String\u003e,\n       body: Value,  // Parsed JSON or string\n       response_time_ms: u64,\n       url: String,  // Final URL after redirects\n   }\n   ```\n\n3. **Request Builder**\n   ```rust\n   struct FetchOptions {\n       method: Method,  // GET, POST, PUT, DELETE, etc.\n       headers: Vec\u003c(String, String)\u003e,\n       body: Option\u003cString\u003e,\n       timeout: Option\u003cDuration\u003e,\n       follow_redirects: bool,\n       output_file: Option\u003cPathBuf\u003e,\n   }\n   ```\n\n4. **Output Modes**\n   - Default: Response body only (like curl)\n   - `--json`: Full structured response\n   - `--headers`: Include headers in text mode\n   - `--verbose`: Full request/response details\n   - `-o file`: Save to file instead of stdout\n\n5. **Error Handling**\n   - Network errors: clear message, non-zero exit\n   - Timeout: specific error, non-zero exit\n   - HTTP errors (4xx, 5xx): include in JSON, exit code reflects status\n   - Invalid URLs: helpful message\n\n## Advanced Features (in scope)\n- Auto-detect JSON responses and parse\n- Support @filename for request body\n- Basic auth: `fetch -u user:pass URL`\n- Custom user agent\n- Progress bar for large downloads (optional)\n\n## NOT in scope (future)\n- Complex auth (OAuth, etc.) - use curl for now\n- Cookies/session management\n- HTTP/2 multiplexing\n- Certificate pinning\n- Proxy support (maybe later)\n\n## Performance Optimization\n- Reuse HTTP client (connection pooling)\n- Async I/O with tokio (reqwest already does this)\n- Streaming for large responses\n- Benchmark vs curl\n\n## Testing Strategy\n- Unit tests: argument parsing, response formatting\n- Integration tests (need test HTTP server):\n  - GET requests\n  - POST with body\n  - Custom headers\n  - Redirects\n  - Timeouts\n  - Error responses\n  - JSON auto-parsing\n- Use httpbin.org for live tests (optional)\n- Mock HTTP server for reliable tests\n\n## Documentation\n- Create docs/HTTP_BUILTIN.md:\n  - All flags and options\n  - Examples for AI agents\n  - Comparison with curl\n  - JSON schema for --json output\n- Add to README\n- Inline help\n\n## Dependencies\n- reqwest = { version = \"0.11\", features = [\"json\", \"blocking\"] }\n  - Consider async vs blocking API\n  - Blocking might be simpler for shell use\n- serde_json (already in use)\n\n## Platform Considerations\n- Use native TLS (OpenSSL on Linux, SChannel on Windows, SecureTransport on macOS)\n- reqwest handles this automatically\n\n## Estimated Effort\n50-60k tokens:\n- Implementation: 20k\n- Request/response handling: 15k\n- Tests: 15k\n- Documentation: 10k","status":"open","priority":3,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","builtin","http","json","p2"],"dependencies":[{"issue_id":"rush-ai.7","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.7","depends_on_id":"rush-ai.4","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.8","title":"AI-008: Structured error responses with error types","description":"As an AI coding agent, I need machine-readable error types so I can respond intelligently to failures instead of parsing error messages.\n\n## Priority: P1 - HIGH\nError handling is critical for AI agents. Exit codes alone are insufficient - agents need to know *why* something failed to take appropriate action.\n\n## Acceptance Criteria\n- [ ] Define standard error type taxonomy\n- [ ] All builtins return typed errors\n- [ ] `RUSH_ERROR_FORMAT=json` environment variable\n- [ ] Errors include: type, message, context, exit_code\n- [ ] `--error-json` flag for command-level override\n- [ ] Backwards compatible: default is text errors\n- [ ] Document all error types\n- [ ] cargo test passes\n- [ ] cargo build --release succeeds\n- [ ] cargo clippy -- -D warnings passes\n\n## Use Cases\n```bash\n# AI agent: Enable JSON errors\nexport RUSH_ERROR_FORMAT=json\n\n# AI agent: Handle git errors intelligently\ngit_status --json 2\u003e error.json\nif [ $? -ne 0 ]; then\n  error_type=$(json_get '.error.type' error.json)\n  case $error_type in\n    \"not_a_git_repo\")\n      echo \"Initializing git repo...\"\n      git init\n      ;;\n    \"permission_denied\")\n      echo \"Need sudo access\"\n      ;;\n    *)\n      echo \"Unknown error: $error_type\"\n      ;;\n  esac\nfi\n\n# Error format example:\n# {\n#   \"error\": {\n#     \"type\": \"not_a_git_repo\",\n#     \"category\": \"git\",\n#     \"message\": \"fatal: not a git repository\",\n#     \"context\": {\n#       \"cwd\": \"/tmp/foo\",\n#       \"command\": \"git_status\"\n#     },\n#     \"exit_code\": 128,\n#     \"suggestion\": \"Run 'git init' to create a new repository\"\n#   }\n# }\n```\n\n## Error Type Taxonomy\n\n### Git Errors\n- `not_a_git_repo`: Not in a git repository\n- `no_upstream`: Branch has no upstream\n- `merge_conflict`: Merge conflict in progress\n- `detached_head`: In detached HEAD state\n- `git_command_failed`: Generic git error\n\n### File Errors\n- `file_not_found`: File doesn't exist\n- `permission_denied`: Insufficient permissions\n- `is_a_directory`: Expected file, got directory\n- `not_a_directory`: Expected directory, got file\n- `disk_full`: No space left on device\n\n### Network Errors (for fetch)\n- `network_unreachable`: No network connection\n- `dns_failed`: DNS resolution failed\n- `connection_timeout`: Request timed out\n- `connection_refused`: Server refused connection\n- `http_error`: HTTP error (4xx, 5xx)\n\n### Parse Errors\n- `invalid_json`: JSON parsing failed\n- `invalid_syntax`: Command syntax error\n- `invalid_argument`: Invalid argument value\n\n### System Errors\n- `command_not_found`: Command doesn't exist\n- `killed_by_signal`: Process terminated by signal\n- `resource_exhausted`: Out of memory/resources\n\n## Technical Implementation\n1. **Create src/error.rs**\n   ```rust\n   #[derive(Debug, Clone, Serialize)]\n   pub struct RushError {\n       pub error_type: ErrorType,\n       pub category: ErrorCategory,\n       pub message: String,\n       pub context: HashMap\u003cString, Value\u003e,\n       pub exit_code: i32,\n       pub suggestion: Option\u003cString\u003e,\n   }\n   \n   #[derive(Debug, Clone, Serialize)]\n   #[serde(rename_all = \"snake_case\")]\n   pub enum ErrorType {\n       // Git\n       NotAGitRepo,\n       NoUpstream,\n       MergeConflict,\n       // File\n       FileNotFound,\n       PermissionDenied,\n       // Network\n       NetworkUnreachable,\n       ConnectionTimeout,\n       HttpError,\n       // Parse\n       InvalidJson,\n       InvalidSyntax,\n       // System\n       CommandNotFound,\n       // ... etc\n   }\n      \n   #[derive(Debug, Clone, Serialize)]\n   #[serde(rename_all = \"lowercase\")]\n   pub enum ErrorCategory {\n       Git,\n       File,\n       Network,\n       Parse,\n       System,\n   }\n   ```\n\n2. **Update ExecutionResult**\n   ```rust\n   pub struct ExecutionResult {\n       pub stdout: String,\n       pub stderr: String,\n       pub exit_code: i32,\n       pub error: Option\u003cRushError\u003e,  // NEW\n   }\n   \n   impl ExecutionResult {\n       pub fn error_typed(error: RushError) -\u003e Self {\n           let stderr = if should_output_json_errors() {\n               serde_json::to_string(\u0026error).unwrap()\n           } else {\n               error.message.clone()\n           };\n           \n           Self {\n               stdout: String::new(),\n               stderr,\n               exit_code: error.exit_code,\n               error: Some(error),\n           }\n       }\n   }\n   ```\n\n3. **Environment Variable Check**\n   ```rust\n   fn should_output_json_errors() -\u003e bool {\n       std::env::var(\"RUSH_ERROR_FORMAT\")\n           .map(|v| v == \"json\")\n           .unwrap_or(false)\n   }\n   ```\n\n4. **Update All Builtins**\n   - Convert string errors to RushError\n   - Add context (cwd, args, etc.)\n   - Add suggestions where helpful\n   - Example:\n     ```rust\n     // Old:\n     return Ok(ExecutionResult::error(\n         \"fatal: not a git repository\\n\".to_string()\n     ));\n     \n     // New:\n     return Ok(ExecutionResult::error_typed(\n         RushError {\n             error_type: ErrorType::NotAGitRepo,\n             category: ErrorCategory::Git,\n             message: \"fatal: not a git repository\".to_string(),\n             context: hashmap!{\n                 \"cwd\" =\u003e json!(runtime.get_cwd()),\n             },\n             exit_code: 128,\n             suggestion: Some(\"Run 'git init' to create a new repository\".to_string()),\n         }\n     ));\n     ```\n\n## Migration Strategy\n1. Add RushError infrastructure (non-breaking)\n2. Update one builtin as example (git_status)\n3. Update remaining builtins incrementally\n4. Ensure backwards compatibility (text by default)\n\n## Testing Strategy\n- Unit tests: error type serialization\n- Integration tests:\n  - Default text errors (backwards compat)\n  - JSON errors with env var\n  - All error types represented\n  - Context includes expected fields\n- Error catalog test: ensure all documented errors exist\n\n## Documentation\n- Create docs/ERROR_HANDLING.md:\n  - Complete error type reference\n  - Examples for each error\n  - AI agent error handling patterns\n  - Migration guide\n- Update builtin docs with error types\n- JSON schema for error format\n\n## Dependencies\n- serde_json (already in use)\n- No new crates needed\n\n## Estimated Effort\n50-60k tokens:\n- Error infrastructure: 15k\n- Update all builtins: 20k\n- Tests: 15k\n- Documentation: 10k","status":"open","priority":2,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","error-handling","infrastructure","p1"],"dependencies":[{"issue_id":"rush-ai.8","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.9","title":"AI-009: Performance benchmarking and optimization for AI agent workloads","description":"As a Rush developer, I need to measure and optimize performance for typical AI agent workloads so Rush is 10x faster than bash+jq.\n\n## Priority: P2 - MEDIUM\nPerformance is a key differentiator. We claim to be fast - let's prove it and optimize bottlenecks.\n\n## Acceptance Criteria\n- [ ] Benchmark suite for AI agent workflows\n- [ ] Comparison benchmarks vs bash+jq+curl\n- [ ] Identify and fix performance bottlenecks\n- [ ] Document performance characteristics\n- [ ] Achieve \u003c5ms for git operations on typical repos\n- [ ] Achieve \u003c1ms for JSON queries on typical data\n- [ ] Achieve 10x speedup vs bash for combined workflows\n- [ ] Continuous performance monitoring setup\n- [ ] cargo test passes\n- [ ] cargo build --release succeeds\n\n## Benchmark Scenarios\n\n### Scenario 1: Git Status Check Loop\n```bash\n# AI agents do this constantly while working\nfor i in {1..100}; do\n  git_status --json \u003e /dev/null\ndone\n# Target: \u003c500ms total (5ms per call)\n# Baseline (bash): ~2000ms (20ms per call)\n```\n\n### Scenario 2: Find + Filter + JSON\n```bash\n# Find all Rust files modified today\nfind --json src/ -name \"*.rs\" -mtime -1 | json_query '.[] | select(.size \u003e 1000)'\n# Target: \u003c10ms for 1000 files\n# Baseline (bash): ~100ms\n```\n\n### Scenario 3: Git Log + Analysis\n```bash\n# Get recent commits and extract authors\ngit_log --json -n 100 | json_get '.[].author' | sort | uniq\n# Target: \u003c50ms\n# Baseline (bash + jq): ~200ms\n```\n\n### Scenario 4: HTTP + JSON Processing\n```bash\n# Fetch API data and extract field\nfetch --json https://api.github.com/repos/rust-lang/rust | json_get '.stargazers_count'\n# Target: Network-bound (no significant overhead)\n# Baseline (curl + jq): Same network time + ~5ms overhead\n```\n\n### Scenario 5: Complex Pipeline\n```bash\n# Realistic AI agent workflow\ngit_status --json | json_get '.unstaged[].path' | \\\n  while read file; do\n    grep --json \"TODO\" \"$file\"\n  done | json_query '.[] | {file, line: .line_number, text: .match}'\n# Target: \u003c100ms for 50 files\n# Baseline (bash): ~500ms\n```\n\n## Technical Implementation\n\n### 1. Benchmark Infrastructure\n```rust\n// benches/ai_agent_workloads.rs\nuse criterion::{black_box, criterion_group, criterion_main, Criterion};\n\nfn bench_git_status_loop(c: \u0026mut Criterion) {\n    c.bench_function(\"git_status_json_100x\", |b| {\n        b.iter(|| {\n            for _ in 0..100 {\n                // Call git_status --json\n                black_box(run_git_status());\n            }\n        });\n    });\n}\n\ncriterion_group!(benches, \n    bench_git_status_loop,\n    bench_find_filter_json,\n    bench_git_log_analysis,\n    // ...\n);\ncriterion_main!(benches);\n```\n\n### 2. Comparison Benchmarks\n```bash\n# benches/compare_bash.sh\n#!/usr/bin/env bash\nset -euo pipefail\n\necho \"Benchmarking Rush vs Bash...\"\n\n# Git status loop\necho \"Git status 100x:\"\ntime for i in {1..100}; do\n  ./target/release/rush -c \"git_status --json\" \u003e /dev/null\ndone\n\ntime for i in {1..100}; do\n  bash -c \"git status --porcelain | jq ...\" \u003e /dev/null\ndone\n\n# More comparisons...\n```\n\n### 3. Profiling Setup\n- Use flamegraph for CPU profiling\n- Use valgrind/heaptrack for memory profiling\n- Use perf for detailed analysis\n- Create profile targets in Cargo.toml\n\n### 4. Optimization Targets\n\n**Git Operations:**\n- Cache git2::Repository handle (don't reopen every call)\n- Lazy load git metadata\n- Parallel file status checking\n- Memoize branch/remote queries\n\n**JSON Operations:**\n- Streaming JSON parser for large files\n- JIT compilation of common queries (future)\n- Avoid unnecessary allocations\n- Use simd-json for parsing (evaluate)\n\n**File Operations:**\n- Parallel directory traversal\n- Memory-mapped file reading for large files\n- Optimize regex compilation (cache)\n\n**General:**\n- Reduce allocations in hot paths\n- Use `Cow\u003cstr\u003e` where appropriate\n- Profile-guided optimization (PGO)\n- Link-time optimization (LTO) already enabled?\n\n## Performance Monitoring\n\n### 1. CI Integration\n- Run benchmarks on every PR\n- Fail if performance regresses \u003e10%\n- Track performance over time\n- Use GitHub Actions + criterion\n\n### 2. Performance Dashboard\n- Generate HTML reports from criterion\n- Publish to GitHub Pages\n- Historical performance graphs\n- Compare across versions\n\n## Testing Strategy\n- Benchmark tests: ensure benchmarks run without errors\n- Regression tests: alert on slowdowns\n- Micro-benchmarks: for specific optimizations\n- Macro-benchmarks: for real-world workflows\n\n## Documentation\n- Create docs/PERFORMANCE.md:\n  - Benchmark results vs bash/zsh\n  - Performance characteristics of each builtin\n  - Optimization techniques used\n  - Tips for AI agents to maximize performance\n- Add to README:\n  - Key benchmark results\n  - \"10x faster\" claims with data\n- Inline comments explaining optimizations\n\n## Deliverables\n1. **Benchmark suite** (benches/ai_agent_workloads.rs)\n2. **Comparison scripts** (benches/compare_bash.sh)\n3. **Performance report** (PERFORMANCE.md)\n4. **Optimization implementations** (various files)\n5. **CI integration** (.github/workflows/bench.yml)\n6. **Performance dashboard** (GitHub Pages)\n\n## Dependencies\n- criterion = \"0.5\" (already in dev-dependencies?)\n- flamegraph (for profiling)\n- No additional runtime dependencies\n\n## Estimated Effort\n40-50k tokens:\n- Benchmark suite: 12k\n- Profiling \u0026 optimization: 15k\n- Comparison benchmarks: 8k\n- CI integration: 5k\n- Documentation: 10k","status":"open","priority":3,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","benchmarking","optimization","p2","performance"],"dependencies":[{"issue_id":"rush-ai.9","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.9","depends_on_id":"rush-ai.1","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.9","depends_on_id":"rush-ai.2","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.9","depends_on_id":"rush-ai.3","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.9","depends_on_id":"rush-ai.4","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
{"id":"rush-ai.10","title":"AI-010: Documentation and examples for AI agent integration","description":"As an AI coding agent developer, I need comprehensive documentation and examples so I can integrate Rush into my agent effectively.\n\n## Priority: P2 - MEDIUM\nEven the best features are useless if AI agents don't know how to use them. Documentation is critical for adoption.\n\n## Acceptance Criteria\n- [ ] Create docs/AI_AGENT_GUIDE.md with complete integration guide\n- [ ] Create docs/AI_AGENT_JSON_REFERENCE.md with all JSON schemas\n- [ ] Add examples/ directory with real-world agent workflows\n- [ ] Update README.md with AI agent section\n- [ ] Create migration guide from bash+jq to Rush\n- [ ] Add inline help for all --json flags\n- [ ] Create video/GIF demos for README\n- [ ] All code examples tested and working\n\n## Documentation Structure\n\n### 1. docs/AI_AGENT_GUIDE.md\n```markdown\n# Rush for AI Coding Agents\n\nComprehensive guide for integrating Rush into AI coding assistants.\n\n## Table of Contents\n1. Why Rush for AI Agents?\n2. Quick Start\n3. Structured Git Operations\n4. JSON Native Operations\n5. File Operations with JSON\n6. HTTP Client\n7. Error Handling\n8. Performance Optimization\n9. Best Practices\n10. Migration from Bash\n\n## Why Rush?\n- **10x faster**: Native Rust, no subprocess overhead\n- **Structured output**: JSON by default, no parsing\n- **Typed errors**: Machine-readable error types\n- **Reliability**: Type-safe, predictable behavior\n- **All-in-one**: Git, JSON, HTTP, file ops built-in\n\n## Quick Start\n### Installation\n```bash\ncargo install rush-shell\n```\n\n### First Steps\n```bash\n# Enable JSON errors for better error handling\nexport RUSH_ERROR_FORMAT=json\n\n# Get repository status\nrush -c \"git_status --json\"\n\n# Find and process files\nrush -c \"find --json src/ -name '*.rs' | json_get '.[].path'\"\n```\n\n## [Continue with detailed sections...]\n```\n\n### 2. docs/AI_AGENT_JSON_REFERENCE.md\n```markdown\n# JSON Schema Reference\n\nComplete reference for all JSON output formats.\n\n## git_status --json\n\n### Schema\n```json\n{\n  \"branch\": \"string | null\",\n  \"tracking\": \"string | null\",\n  \"ahead\": \"number\",\n  \"behind\": \"number\",\n  \"state\": \"clean | merge | rebase | cherry-pick\",\n  \"staged\": [\n    {\n      \"path\": \"string\",\n      \"status\": \"modified | added | deleted | renamed\"\n    }\n  ],\n  // ... etc\n}\n```\n\n### Example\n[Include real example]\n\n### Fields\n- `branch`: Current branch name, null if detached HEAD\n- `tracking`: Remote tracking branch, null if none\n- `ahead`: Number of commits ahead of tracking\n- ...\n\n## [Continue for all commands...]\n```\n\n### 3. examples/\n\nCreate real-world example workflows:\n\n**examples/commit_message_generator.rush**\n```bash\n#!/usr/bin/env rush\n# Generate intelligent commit messages from git diff\n\nset -e\nexport RUSH_ERROR_FORMAT=json\n\n# Get staged changes\ndiff=$(git_diff --json --staged)\n\nif [ \"$(echo \"$diff\" | json_get '.summary.files_changed')\" = \"0\" ]; then\n  echo \"No staged changes\"\n  exit 1\nfi\n\n# Extract file changes\nfiles=$(echo \"$diff\" | json_get '.files[].path' | head -5)\ninsertions=$(echo \"$diff\" | json_get '.summary.insertions')\ndeletions=$(echo \"$diff\" | json_get '.summary.deletions')\n\n# Generate message\necho \"Update $files\"\necho \"\"\necho \"Changed files: $(echo \"$diff\" | json_get '.summary.files_changed')\"\necho \"+$insertions -$deletions lines\"\n```\n\n**examples/find_todos.rush**\n```bash\n#!/usr/bin/env rush\n# Find all TODO comments in codebase with context\n\ngrep --json \"TODO\" src/**/*.rs | \\\n  json_query '.[] | {file, line: .line_number, todo: .match}' | \\\n  json_get '.[] | \"\\(.file):\\(.line) - \\(.todo)\"'\n```\n\n**examples/dependency_check.rush**\n```bash\n#!/usr/bin/env rush\n# Check if dependencies are up to date\n\nset -e\n\n# Fetch latest crate info\nfor crate in $(json_get '.dependencies | keys[]' Cargo.toml); do\n  latest=$(fetch --json \"https://crates.io/api/v1/crates/$crate\" | \\\n           json_get '.crate.max_version')\n  current=$(json_get \".dependencies.$crate\" Cargo.toml)\n  \n  if [ \"$current\" != \"$latest\" ]; then\n    echo \"$crate: $current -\u003e $latest\"\n  fi\ndone\n```\n\n**examples/code_review_prep.rush**\n```bash\n#!/usr/bin/env rush\n# Prepare code review summary\n\nset -e\n\n# Get commit range\nbase_branch=\"origin/main\"\ncurrent_branch=$(git_status --json | json_get '.branch')\n\necho \"# Code Review: $current_branch\"\necho \"\"\n\n# Commit summary\necho \"## Commits\"\ngit_log --json \"$base_branch..$current_branch\" | \\\n  json_get '.[].message' | \\\n  while read -r msg; do\n    echo \"- $msg\"\n  done\n\necho \"\"\necho \"## Files Changed\"\ngit_diff --json \"$base_branch..HEAD\" --stat | \\\n  json_get '.files[] | \"\\(.path): +\\(.additions) -\\(.deletions)\"'\n\necho \"\"\necho \"## TODOs Added\"\ngit_diff --json \"$base_branch..HEAD\" | \\\n  json_query '.files[].hunks[].changes[] | select(.type == \"add\" and .line | contains(\"TODO\"))'\n```\n\n### 4. README.md Updates\n\nAdd prominent section:\n```markdown\n## For AI Coding Agents\n\nRush is designed for AI agents that make hundreds of shell calls per task.\n\n### Why Rush?\n- **10x faster** than bash+jq for typical agent workflows\n- **Structured output**: All commands support `--json` flag\n- **Typed errors**: Machine-readable error types for intelligent error handling\n- **All-in-one**: Git, JSON, HTTP, file operations built-in\n\n### Quick Example\n```bash\n# Get repository status and analyze changes\nrush -c \"git_status --json | json_get '.unstaged[] | select(.status == \\\"modified\\\")'\"\n\n# Find all TODO comments with context\nrush -c \"grep --json 'TODO' src/**/*.rs | json_query '.[] | {file, line, text}'\"\n\n# Fetch API data and extract fields\nrush -c \"fetch --json https://api.github.com/repos/rust-lang/rust | json_get '.stargazers_count'\"\n```\n\n### Documentation\n- [AI Agent Integration Guide](docs/AI_AGENT_GUIDE.md)\n- [JSON Schema Reference](docs/AI_AGENT_JSON_REFERENCE.md)\n- [Example Workflows](examples/)\n- [Performance Benchmarks](docs/PERFORMANCE.md)\n\n### Benchmarks\n| Operation | Rush | Bash+jq | Speedup |\n|-----------|------|---------|----------|\n| git_status 100x | 500ms | 2000ms | 4x |\n| find + filter | 10ms | 100ms | 10x |\n| git_log + parse | 50ms | 200ms | 4x |\n| Complex pipeline | 100ms | 500ms | 5x |\n```\n\n### 5. Video/GIF Demos\n\nCreate demos showing:\n1. Rush vs bash speed comparison (side-by-side)\n2. JSON output and querying\n3. Error handling with typed errors\n4. Complex workflow example\n\nUse asciinema or similar for terminal recordings.\n\n## Testing Strategy\n- All code examples must be tested\n- Create tests/docs_examples.rs that runs all examples\n- Ensure examples work with current Rush version\n- Update examples when APIs change\n\n## Deliverables\n1. **AI_AGENT_GUIDE.md** - Complete integration guide\n2. **AI_AGENT_JSON_REFERENCE.md** - All JSON schemas\n3. **examples/** - 10+ working examples\n4. **README.md** - Updated with AI agent section\n5. **Migration guide** - Bash to Rush conversion\n6. **Video demos** - 3-5 demo recordings\n7. **Inline help** - All commands have --help with JSON info\n\n## Dependencies\n- No new dependencies\n- asciinema or vhs for terminal recordings\n\n## Estimated Effort\n45-55k tokens:\n- AI_AGENT_GUIDE.md: 15k\n- AI_AGENT_JSON_REFERENCE.md: 10k\n- Examples: 10k\n- README updates: 5k\n- Migration guide: 8k\n- Video demos: 7k","status":"open","priority":3,"issue_type":"task","owner":"a@kf.cafe","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude","updated_at":"2026-01-24T12:00:00-08:00","labels":["ai-agents","documentation","examples","p2"],"dependencies":[{"issue_id":"rush-ai.10","depends_on_id":"rush-ai","type":"parent-child","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.1","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.2","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.3","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.4","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.5","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.6","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.7","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"},{"issue_id":"rush-ai.10","depends_on_id":"rush-ai.8","type":"depends-on","created_at":"2026-01-24T12:00:00-08:00","created_by":"Claude"}]}
