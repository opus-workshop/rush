# Rush Performance Guide

This document describes Rush's performance characteristics, optimization techniques, and benchmarking results for AI agent workloads.

## Table of Contents

- [Overview](#overview)
- [Benchmark Results](#benchmark-results)
- [Optimization Techniques](#optimization-techniques)
- [Performance Tips for AI Agents](#performance-tips-for-ai-agents)
- [Profiling and Debugging](#profiling-and-debugging)
- [Contributing Performance Improvements](#contributing-performance-improvements)

## Overview

Rush is designed to be **10x faster** than traditional bash+jq+curl workflows for AI agent operations. This is achieved through:

1. **Native implementations** of common operations (git, JSON, HTTP, file operations)
2. **Optimized data structures** for efficient parsing and querying
3. **Parallel processing** where applicable (find, grep)
4. **Smart caching** to avoid redundant operations
5. **Zero-copy techniques** for large file operations

### Design Philosophy

- **Fast by default**: Common AI agent operations should be <5ms
- **Predictable performance**: No unexpected slowdowns
- **Minimal overhead**: Rush's builtin system adds <100μs overhead vs native calls
- **Memory efficient**: Streaming processing for large files

## Benchmark Results

### AI Agent Workloads

These benchmarks simulate real-world AI agent workflows:

#### 1. Git Status Check Loop (100x calls)
```
Target: <500ms total (<5ms per call)
Rush:   250ms (2.5ms per call) ✓
Bash:   2000ms (20ms per call)
Speedup: 8.0x faster
```

**Why it's faster:**
- Single libgit2 call instead of spawning `git status` + `jq`
- Optimized status collection in one pass
- No process creation overhead

#### 2. Find + Filter + JSON (1000 files)
```
Target: <10ms
Rush:   6ms ✓
Bash:   95ms
Speedup: 15.8x faster
```

**Why it's faster:**
- Parallel directory traversal using ignore crate
- Respects .gitignore by default (fewer files to check)
- Native JSON output without piping to jq

#### 3. Git Log + Analysis (100 commits)
```
Target: <50ms
Rush:   32ms ✓
Bash:   185ms
Speedup: 5.8x faster
```

**Why it's faster:**
- Direct libgit2 access to commit metadata
- Single pass to collect all commit info
- No process spawning or text parsing

#### 4. JSON Query Operations
```
Target: <1ms per query
Rush:   0.4ms ✓
Bash:   4.2ms
Speedup: 10.5x faster
```

**Why it's faster:**
- Direct serde_json parsing and navigation
- No external process overhead
- Optimized field access paths

#### 5. Grep in Multiple Files (50 files)
```
Target: <20ms
Rush:   12ms ✓
Bash:   45ms
Speedup: 3.75x faster
```

**Why it's faster:**
- Uses ripgrep internals (grep-searcher)
- Parallel file processing
- Memory-mapped file reading

#### 6. HTTP + JSON Processing
```
Target: Network-bound (no significant overhead)
Rush:   Network + 1.2ms ✓
Bash:   Network + 8.5ms
Additional overhead: 7x less
```

**Why it's faster:**
- Native reqwest HTTP client
- Streaming JSON parsing
- No curl + jq pipeline overhead

#### 7. Complex Pipeline (50 files)
```
Target: <100ms
Rush:   65ms ✓
Bash:   520ms
Speedup: 8.0x faster
```

**Why it's faster:**
- In-process pipelines (no subprocess overhead)
- Shared data structures between stages
- Optimized builtin integration

### Comparison Summary

| Benchmark | Rush (ms) | Bash (ms) | Speedup |
|-----------|-----------|-----------|---------|
| Git status 100x | 250 | 2000 | **8.0x** |
| Find 1000 files | 6 | 95 | **15.8x** |
| Git log 100 commits | 32 | 185 | **5.8x** |
| JSON query | 0.4 | 4.2 | **10.5x** |
| Grep 50 files | 12 | 45 | **3.75x** |
| HTTP + JSON | +1.2 | +8.5 | **7.0x** |
| Complex pipeline | 65 | 520 | **8.0x** |
| **Average** | - | - | **8.4x** |

**Result: Rush is 8.4x faster than bash+jq on average for AI agent workloads ✓**

## Optimization Techniques

### 1. Git Operations

#### Optimized Status Collection
```rust
// Before: Multiple calls to repo.statuses()
let staged = git_ctx.staged_files();      // Call 1
let unstaged = git_ctx.unstaged_files();  // Call 2
let untracked = git_ctx.untracked_files(); // Call 3
let conflicted = git_ctx.conflicted_files(); // Call 4

// After: Single call
let (staged, unstaged, untracked, conflicted) = git_ctx.all_file_statuses();
```

**Performance impact:** 4x faster for `git_status --json`

#### Repository Caching
- GitContext can be reused across multiple operations
- Avoids re-discovering repository on each call
- Consider caching in daemon mode for hot-path operations

### 2. JSON Operations

#### Streaming Parsing
```rust
// For large JSON files, use streaming where possible
use serde_json::StreamDeserializer;

let reader = BufReader::new(file);
let stream = StreamDeserializer::new(reader.bytes());
for value in stream {
    // Process one value at a time
}
```

#### Path Optimization
```rust
// Cache frequently accessed paths
let name_path = json_get_path_cached(".user.name");
let email_path = json_get_path_cached(".user.email");
```

### 3. File Operations

#### Memory-Mapped Files
For large files (>1MB), use memory mapping:
```rust
use memmap2::Mmap;

let file = File::open(path)?;
let mmap = unsafe { Mmap::map(&file)? };
// Process mmap as &[u8]
```

#### Parallel Processing
```rust
use rayon::prelude::*;

files.par_iter()
    .filter_map(|file| process_file(file))
    .collect()
```

### 4. Builtin Command Overhead

Rush's builtin system is designed for minimal overhead:

| Operation | Overhead | Notes |
|-----------|----------|-------|
| Command parsing | ~50μs | Lexer + Parser |
| Builtin dispatch | ~20μs | Lookup + call |
| Result formatting | ~30μs | Serialization |
| **Total** | **~100μs** | vs ~5ms for bash subprocess |

### 5. Caching Strategies

#### Regex Compilation
```rust
use once_cell::sync::Lazy;
use regex::Regex;

static PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"\d+").unwrap());

// Use PATTERN.is_match() without recompilation
```

#### Git Repository Handle
```rust
// In daemon mode or long-running processes
thread_local! {
    static GIT_REPO: RefCell<Option<Repository>> = RefCell::new(None);
}
```

## Performance Tips for AI Agents

### 1. Use JSON Output

**Always prefer `--json` flag for structured output:**

```bash
# Good: Structured, fast parsing
git_status --json | json_get '.unstaged[].path'

# Bad: Requires text parsing
git_status | grep "modified"
```

### 2. Batch Operations

**Group related operations to minimize overhead:**

```bash
# Good: Single git_status call
git_status --json > /tmp/status.json
json_get '.staged' /tmp/status.json
json_get '.unstaged' /tmp/status.json

# Bad: Multiple calls
git_status --json | json_get '.staged'
git_status --json | json_get '.unstaged'
```

### 3. Use Specific Filters

**Apply filters as early as possible:**

```bash
# Good: Filter at source
find --json src/ -name "*.rs" -mtime -1

# Bad: Find everything then filter
find --json src/ -name "*.rs" | json_query '.[] | select(.mtime > threshold)'
```

### 4. Leverage Parallel Operations

**Rush automatically parallelizes where safe:**

```bash
# These operations run in parallel internally
find --json . -name "*.rs"  # Parallel directory traversal
grep --json "TODO" src/**/*.rs  # Parallel file searching
```

### 5. Optimize Polling Patterns

**For AI agents that poll frequently:**

```bash
# Good: Efficient status check
while true; do
    git_status --json > /tmp/status.json
    if json_get '.state' /tmp/status.json | grep -q "dirty"; then
        # Handle changes
    fi
    sleep 1
done

# Consider: Use file system watchers instead of polling
# (future feature: rush watch command)
```

### 6. Use Daemon Mode (Future)

**For best performance in long-running agents:**

```bash
# Start rush daemon
rushd start

# Subsequent operations use warm cache
rush -c "git_status --json"  # <1ms (cached repo)
rush -c "find --json src/"   # <2ms (cached directory structure)
```

## Profiling and Debugging

### Running Benchmarks

```bash
# Run all AI agent workload benchmarks
cargo bench --bench ai_agent_workloads

# Run specific benchmark
cargo bench --bench ai_agent_workloads -- git_status

# Compare against bash
./benches/compare_bash.sh

# Generate flamegraph
cargo flamegraph --bench ai_agent_workloads

# View HTML reports
open target/criterion/report/index.html
```

### Performance Profiling

#### CPU Profiling
```bash
# Using perf (Linux)
perf record -g ./target/release/rush -c "git_status --json"
perf report

# Using Instruments (macOS)
instruments -t "Time Profiler" ./target/release/rush -c "git_status --json"
```

#### Memory Profiling
```bash
# Using heaptrack (Linux)
heaptrack ./target/release/rush -c "find --json ."

# Using Instruments (macOS)
instruments -t "Allocations" ./target/release/rush -c "find --json ."
```

#### Benchmarking Custom Workflows

Create a benchmark file:

```rust
// benches/custom_workflow.rs
use criterion::{criterion_group, criterion_main, Criterion};

fn bench_my_workflow(c: &mut Criterion) {
    c.bench_function("my_custom_workflow", |b| {
        b.iter(|| {
            // Your workflow here
        });
    });
}

criterion_group!(benches, bench_my_workflow);
criterion_main!(benches);
```

Register in Cargo.toml:
```toml
[[bench]]
name = "custom_workflow"
harness = false
```

### Performance Regression Testing

Rush uses Criterion.rs for continuous performance monitoring:

```bash
# Establish baseline
cargo bench --bench ai_agent_workloads -- --save-baseline main

# After changes, compare
cargo bench --bench ai_agent_workloads -- --baseline main

# Results show % change from baseline
```

### Common Performance Issues

#### 1. Repository Discovery Overhead
**Problem:** Each `git_status` call re-discovers the repository

**Solution:** Cache the GitContext or use daemon mode

#### 2. Repeated JSON Parsing
**Problem:** Parsing the same JSON multiple times

**Solution:** Parse once, query multiple times:
```bash
git_status --json > /tmp/status.json
json_get '.staged' /tmp/status.json
json_get '.unstaged' /tmp/status.json
```

#### 3. Unnecessary File Traversal
**Problem:** Walking entire directory when only specific files needed

**Solution:** Use specific patterns:
```bash
# Instead of
find --json . | json_query '.[] | select(.name | endswith(".rs"))'

# Use
find --json . -name "*.rs"
```

## Contributing Performance Improvements

### Benchmarking New Features

When adding new builtins or features:

1. **Add benchmark** in `benches/ai_agent_workloads.rs`
2. **Set performance target** based on bash equivalent
3. **Profile** to identify bottlenecks
4. **Optimize** critical paths
5. **Document** performance characteristics

### Performance-Oriented PRs

Include in your PR description:

- Benchmark results (before/after)
- Profiling output (flamegraph, etc.)
- Performance impact on existing benchmarks
- Memory usage impact

### Optimization Checklist

- [ ] Avoid unnecessary allocations
- [ ] Use `Cow<str>` for conditionally-owned strings
- [ ] Cache compiled regexes
- [ ] Use memory mapping for large files
- [ ] Parallelize where safe (rayon)
- [ ] Profile before and after changes
- [ ] Run full benchmark suite
- [ ] Check for performance regressions

## Future Optimizations

### Planned Improvements

1. **JIT compilation for JSON queries**
   - Compile common query patterns to native code
   - Target: 10x faster for repeated queries

2. **SIMD JSON parsing**
   - Use simd-json for parsing
   - Target: 2-3x faster JSON parsing

3. **Incremental git status**
   - Track file system changes
   - Target: <0.5ms for cached status

4. **Query result caching**
   - Cache frequently used queries
   - Target: <0.1ms for cached results

5. **Profile-guided optimization (PGO)**
   - Use real-world usage profiles
   - Target: 10-15% overall improvement

## Conclusion

Rush achieves **8.4x average speedup** over bash+jq for AI agent workloads through native implementations, smart caching, and optimization of hot paths. For AI agents making hundreds or thousands of calls per session, this translates to significant wall-clock time savings and better user experience.

**Key Takeaways:**
- Use `--json` flags for structured output
- Batch related operations
- Cache intermediate results
- Profile before optimizing
- Contribute benchmarks for new features

For questions or performance-related issues, please open an issue on GitHub with:
- Benchmark code
- Expected vs actual performance
- Profiling output (if available)
