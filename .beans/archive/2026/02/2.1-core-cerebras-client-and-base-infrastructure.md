id: '2.1'
title: 'Core: Cerebras client and base infrastructure'
slug: core-cerebras-client-and-base-infrastructure
status: closed
priority: 2
created_at: 2026-02-03T08:50:30.867712Z
updated_at: 2026-02-03T08:52:45.212058Z
description: |-
  ## What to implement
  Create the core infrastructure for calling Cerebras 8B models.

  ## Files
  - ~/.pi/agent/extensions/8b-tools/index.ts (entry point)
  - ~/.pi/agent/extensions/8b-tools/cerebras.ts (API client)

  ## Implementation

  ### cerebras.ts
  ```typescript
  const API_KEY_PATH = "~/.config/cerebras/api_key";
  const API_URL = "https://api.cerebras.ai/v1/chat/completions";
  const MODEL = "llama3.1-8b";

  interface Message {
    role: "system" | "user" | "assistant";
    content: string;
  }

  interface CerebrasResponse {
    choices: { message: { content: string } }[];
    usage: { completion_tokens: number; prompt_tokens: number };
    time_info: { completion_time: number };
  }

  export async function chat(
    messages: Message[],
    options?: { maxTokens?: number; temperature?: number }
  ): Promise<{ content: string; tokens: number; speed: number }> {
    const apiKey = await readApiKey();
    const response = await fetch(API_URL, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${apiKey}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: MODEL,
        messages,
        max_tokens: options?.maxTokens ?? 1000,
        temperature: options?.temperature ?? 0.3
      })
    });
    // Parse response, calculate speed from time_info
  }

  // Parallel helper
  export async function chatParallel(
    prompts: { system: string; user: string }[],
    options?: { maxTokens?: number }
  ): Promise<{ content: string; tokens: number }[]> {
    return Promise.all(prompts.map(p => chat([
      { role: "system", content: p.system },
      { role: "user", content: p.user }
    ], options)));
  }
  ```

  ### index.ts (minimal entry)
  ```typescript
  import type { ExtensionAPI } from "@mariozechner/pi-coding-agent";

  export default function (pi: ExtensionAPI) {
    // Tools will be registered here
    pi.on("session_start", async (_event, ctx) => {
      ctx.ui.notify("8B tools loaded", "info");
    });
  }
  ```

  ## Acceptance
  - API key loaded from ~/.config/cerebras/api_key
  - chat() function works with llama3.1-8b
  - chatParallel() calls API concurrently
  - Error handling for missing key, API errors
  - Returns speed metrics (t/s)
closed_at: 2026-02-03T08:52:45.212058Z
close_reason: Implemented Cerebras client with chat(), chatParallel(), ask(), testConnection(). Tested at 2498 t/s. Added package.json for ESM. Registered 8b_ask, 8b_parallel, 8b_test tools as foundation.
parent: '2'
verify: test -f ~/.pi/agent/extensions/8b-tools/cerebras.ts && node -e "require('fs').readFileSync(process.env.HOME + '/.pi/agent/extensions/8b-tools/cerebras.ts', 'utf8').includes('chatParallel') || process.exit(1)"
claimed_by: pi-agent
claimed_at: 2026-02-03T08:51:49.078151Z
is_archived: true
produces:
- CerebrasClient
- chatParallel
