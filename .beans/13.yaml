id: '13'
title: Performance Profiling Built-in
status: open
priority: 1
created_at: 2026-01-30T18:49:24.332544Z
updated_at: 2026-01-30T18:49:24.332544Z
description: "Add built-in performance profiling to show where time is spent during command execution.\n\n## Problem\nUsers criticize 4.0ms startup vs bash's 2.5ms. Turn this into a feature by showing that fast builtins compensate. Demonstrate transparency and observability.\n\n## Success Criteria\n- `rush --profile -c 'command'` shows timing breakdown\n- Profiling available as builtin: `profile { commands }`\n- Shows: startup time, parse time, execution time per command\n- Differentiates builtin vs external command performance\n- Pipeline stage timing breakdown\n- Optional: Memory usage tracking\n- Zero overhead when not profiling\n- Clean, readable output format\n\n## User Stories\n1. As a developer, I want to see where time is spent so I understand performance characteristics\n2. As a user, I want to profile my scripts so I can optimize bottlenecks\n3. As a Rush advocate, I want to show how fast builtins compensate for startup overhead\n\n## Example Output\n```\n$ rush --profile -c 'ls | grep foo'\nPerformance Profile:\n  Shell startup:    4.0ms\n  Parse:            0.2ms\n  Execute 'ls':     0.1ms (builtin, 17x faster than GNU)\n  Execute 'grep':   0.05ms (builtin, 212x faster than GNU)\n  Pipeline setup:   0.1ms\n  Total:            4.45ms\n  \nComparison: bash -c 'ls | grep foo' = 12.3ms (2.8x slower)\n```\n\n## Technical Notes\n- Use `std::time::Instant` for high-resolution timing\n- Add timing checkpoints in executor\n- Store metrics in executor state\n- Output formatter for human-readable display\n- Optional JSON output for tooling\n- Add `--profile-memory` for memory tracking (future)\n\n## Deliverables\n- `--profile` CLI flag\n- `profile` builtin command\n- Timing infrastructure in executor\n- Human-readable formatter\n- JSON output mode\n- Documentation and examples"
labels:
- feature
- hn-feature
- observability
- performance
- phase4
