id: '12'
title: Benchmark Reproducibility Suite
status: open
priority: 1
created_at: 2026-01-30T18:49:24.328584Z
updated_at: 2026-01-30T18:49:24.328584Z
description: |-
  Create a comprehensive benchmark suite that users can run locally to verify Rush's performance claims.

  ## Problem
  The #1 HN criticism will be "I don't trust these 225x/427x speedup claims." Users need to reproduce benchmarks on their own hardware.

  ## Success Criteria
  - User-friendly benchmark runner: `rush --benchmark`
  - Quick mode for smoke testing: `rush --benchmark quick`
  - Comparison mode: `rush --benchmark compare` (Rush vs bash/zsh)
  - Generates detailed HTML reports with charts
  - Includes all benchmarked operations (cat, ls, find, grep, startup)
  - Works on macOS and Linux
  - Documents methodology and fairness
  - Results saved to `benchmark_results.json`
  - Can export to markdown for sharing

  ## User Stories
  1. As a skeptical developer, I want to run benchmarks locally so I can verify performance claims
  2. As a potential user, I want quick smoke tests so I can see if Rush is faster on my hardware
  3. As a contributor, I want reproducible benchmarks so I can track performance regressions

  ## Technical Notes
  - Build on existing criterion benchmarks
  - Add hyperfine integration for real-world comparisons
  - Include warmup runs to eliminate cold start bias
  - Document test data generation (file sizes, counts)
  - Ensure fair comparison (same operations, same data)
  - Add CI integration to track performance over time

  ## Deliverables
  - `scripts/user_benchmark.sh` - Main benchmark runner
  - `scripts/quick_benchmark.sh` - Fast smoke test
  - Markdown report generation
  - HTML visualization (using criterion's output)
  - Documentation in docs/BENCHMARKING.md
labels:
- benchmarking
- hn-feature
- observability
- phase4
